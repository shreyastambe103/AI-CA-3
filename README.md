# Disease Diagnosis and Report Generation
This project uses deep learning to automate disease classification and view position identification in chest X-ray images, enhancing diagnostic accuracy and efficiency. It is built on DenseNet, a state-of-the-art convolutional neural network, the model accurately identifies diseases and view positions. In order to improve interpretability and clinician trust, it uses explainable AI techniques such as LIME and GRAD-CAM to visually emphasise diagnostic regions. The system then generates detailed radiology reports, by combining classification results, diagnostic areas, and patient data, offering radiologists with a useful tool to help them make fast and accurate judgements. The accuracy of the resulted diseases are 88.26% and 99.7% for view position. The model takes large amount of time to accurately highlight the diagnostic regions and high computation powers.

![Screenshot 2024-11-16 142646](https://github.com/user-attachments/assets/e36849b0-5409-4a5e-8601-b03eeb6e020b)
